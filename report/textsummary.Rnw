\documentclass{article}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[margin=0.70in]{geometry}
\setlength{\parindent}{0in}
\title{Unsupervised Method Summarizing News Articles}
\author{Alex Shum, Robert }

\begin{document}
\maketitle

\section*{Introduction}
Summarizing a news article is the process of reducing the original document text into a few brief overall key points.  A good summarization should be both concise and still retain all the important elements from the original text.  There are two main classes of methods for summarization: abstractive and extractive[1].  Abstractive summarization methods generate new text that will paraphrase the article.  These techniques seek to create summaries close to what a person might write to generalize an article.  By contrast, extractive techniques do not generate any text and will simply extract the most relevent sentences from the article.  Extractive methods can only return summaries containing text that was present in the original article.  The methods and results presented will be limited to extractive techniques.\\
\\
Among extractive techniques there are many approaches to rank sentences and phrases within an article.  Common extractive tasks include keyphrase detection and sentence extraction -- finding the most relevant keyword or sentence.  Our goal is to summarize the overall content of a news article and our focus will be implementing an extractive method to find the most relevant sentences to summarize a news article.  The method implemented in this project is TextRank; TextRank is an unsupervised method similar to the PageRank algorithm for webpages.  Included below is a brief overview of extractive methods, an explanation of the TextRank algorithm, implementation issues and our results and conclusion.

\section*{Background}
One of the first uses for automatic summarization was to automate finding keywords or keyphrases for journal papers.  An early solution to this problem was a supervised technique; keyphrases were assigned by readers for various collections of documents and a decision tree algorithm was used to classify text as a keyphrase or not [3].  This supervised method would look at the length of the text, frequency, if the text contains nouns or verbs and a few other features to train a model to predict if a string of text is a keyphrase or not.  A decision tree method is able to determine which features are important for keyphrases but unfortunately the supervised nature of this method requires both training data and intelligent feature selection.\\
\\
Another possible approach to automatic summarization is to use latent semantic analysis [4].  The document can be represented as an $m \times n$ matrix with sentences representing the $m$ unique word and $n$ sentences in the document.  The columns of this matrix represent the sentences in the document.  Distance between sentences are given by the cosine distance: $d(\vec{s_1}, \vec{s_2}) = \frac{\vec{s_1} \cdot \vec{s_2}}{|\vec{s_1}||\vec{s_2}|}$.  The most relevant sentences should be have the shortest average distance to other sentences.  Alternatively, its possible rank based on the sentence with the highest singular value from the singular value decomposition.\\
\\
More recently a few graph based methods based on the PageRank algorithm have been proposed for this problem.  The PageRank algorithm represents webpages as vertices in a graph with edges representing links between pages.  PageRank ranks webpages based on the link structure; important webpages are linked to by other important webpages [6].  This idea is extended to sentences in a document; important sentences are similar to other important sentences.  TextRank and LexRank are two algorithms that rank sentences based on this idea [2][5].  These two algorithms represent sentences in a document as vertices and edges based on a distance metric between sentences.  We give a more detailed description of the TextRank algorithm in the next section.

\section*{Method}


\section*{Implementation}
The summarizer's code is split between 7 java class files. The most important file is the SummaryBot.java file that defines a SumamryBot object. A SummaryBot is meant to take in text or a text file containing an article and summarize it down to just a few sentences. To do this it first extracts the text from the file if needed, then send it to a ISentenceProcessor object. The point of the SentenceProcessor object is to separate the text into sentences and remove unnecessary or irrelevant words. Initially we tried to implement ours in OPenNLPSentenceProcessor.java which uses the OpenNLP library to do both parts, however, we found the word removal to work too slowly. To remedy this we Created LuceneSentenceProcessor.java which uses OpenNLP to separate sentences and the Lucene library to remove extra words.\\
\\
After being processed, the sentences are passed to the CreateCommonMatrix method in MiscUtils.java which creates a matrix where each position i,j represents the number of words shared between sentences i and j. Then the matrix is sent to the IRanker object which uses some method to rank the sentences based on values in the matrix. We implemented using the PageRanker class which uses a variation on the PageRank algorithm to accomplish this task. Finally, with the results from the Ranker object, the SummaryBot is able to print the X best sentences for summarizing the article.

\section*{Results}
To test our summarizer, we took six articles and ran it through four different summarizers including ours. We then looked to see how many sentences were summarized by ours and by the others.\\
\\
Here are the results of testing our summarizer. If you want more details such as what sentences were actually generated by each summarizer, refer to the results.txt document.\\
\\
Note: it's necessary to add how many sentences could have been smilar since the online summarizers sometimes use less than five sentences.\\
\\
Article 1:\\summarizer 2: 1 out of 3 sentences were similar\\summarizer 3: 1 out of 4 sentences were similar\\summarizer 4: 0 out of 5 sentences were similar\\
\\
Although 4 of the 5 sentences our summarizer came up with were different, they still centered around the article's main topic.\\
\\
Article 2:\\summarizer 2: 2 out of 4 sentences were similar\\summarizer 3: 2 out of 5 sentences were similar\\summarizer 4: 1 out of 5 sentences were similar\\
\\
Again, the three sentences that weren't similar still provide important knowledge to the summary.\\
\\
Article 3:\\summarizer 2: 0 out of 4 sentences were similar\\summarizer 3: 0 out of 5 sentences were similar\\summarizer 4: 2 out of 5 sentences were similar\\
\\
In this article, none of the summarizers had very many similar sentences to eachother, but all summarized it well.
\\
Article 4:\\summarizer 2: 3 out of 5 sentences were similar\\summarizer 3: 3 out of 5 sentences were similar\\summarizer 4: 2 out of 5 sentences were similar\\
\\
The two sentences not similar were still good pieces of information.\\
\\
Article 5:\\summarizer 2: 2 out of 5 sentences were similar\\summarizer 3: 3 out of 5 sentences were similar\\summarizer 4: 0 out of 5 sentences were similar\\
\\
For whatever reason, in this article The last online summarizer did a poor job of summarizing, so it's probably good it didn't share any similar sentences with ours.\\
\\
Article 6:\\summarizer 2: 3 out of 4 sentences were similar\\summarizer 3: 3 out of 4 sentences were similar\\summarizer 4: 4 out of 5 sentences were similar\\
\\
In this article only 1 sentences was not also summarized by the other ones.

\section*{Conclusion}

%citation
%overview
%1. http://pages.cs.wisc.edu/~goldberg/publications/summarization.pdf
%textrank
%2. http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf
%supervised
%3. http://www.extractor.com/IR2000.pdf
%LSA
%4. http://www.kiv.zcu.cz/~jstein/publikace/isim2004.pdf
%lexrank
%5. http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html
%pagerank
%6. http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf
%7. Lucene
%8. OpenNLP

\end{document}