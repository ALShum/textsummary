\documentclass{article}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[margin=0.70in]{geometry}
\setlength{\parindent}{0in}
\title{Unsupervised Method Summarizing News Articles}
\author{Alex Shum, Robert }

\begin{document}
\maketitle

\section*{Introduction}
Summarizing a news article is the process of reducing the original document text into a few brief overall key points.  A good summarization should be both concise and still retain all the important elements from the original text.  There are two main classes of methods for summarization: abstractive and extractive[1].  Abstractive summarization methods generate new text that will paraphrase the article.  These techniques seek to create summaries close to what a person might write to generalize an article.  By contrast, extractive techniques do not generate any text and will simply extract the most relevent sentences from the article.  Extractive methods can only return summaries containing text that was present in the original article.  The methods and results presented will be limited to extractive techniques.\\
\\
Among extractive techniques there are many approaches to rank sentences and phrases within an article.  Common extractive tasks include keyphrase detection and sentence extraction -- finding the most relevant keyword or sentence.  Our goal is to summarize the overall content of a news article and our focus will be implementing an extractive method to find the most relevant sentences to summarize a news article.  The method implemented in this project is TextRank; TextRank is an unsupervised method similar to the PageRank algorithm for webpages.  Included below is a brief overview of extractive methods, an explanation of the TextRank algorithm, implementation issues and our results and conclusion.

\section*{Background}
One of the first uses for automatic summarization was to automate finding keywords or keyphrases for journal papers.  An early solution to this problem was a supervised technique; keyphrases were assigned by readers for various collections of documents and a decision tree algorithm was used to classify text as a keyphrase or not [3].  This supervised method would look at the length of the text, frequency, if the text contains nouns or verbs and a few other features to train a model to predict if a string of text is a keyphrase or not.  A decision tree method is able to determine which features are important for keyphrases but unfortunately the supervised nature of this method requires both training data and domain knowledge for feature selection.\\
\\
Another possible approach to automatic summarization is to use latent semantic analysis [4].  The document can be represented as an $m \times n$ matrix with sentences representing the $m$ unique word and $n$ sentences in the document.  The columns of this matrix represent the sentences in the document.  Distance between sentences are given by the cosine distance: $d(\vec{s_1}, \vec{s_2}) = \frac{\vec{s_1} \cdot \vec{s_2}}{|\vec{s_1}||\vec{s_2}|}$.  The most relevant sentences should be have the shortest average distance to other sentences.  Alternatively, latent semantic analysis utilizes a singular value decomposition and it is also possible to rank sentences based on the highest singular value.\\
\\
More recently a few graph based methods based on the PageRank algorithm have been proposed for this problem.  The PageRank algorithm represents webpages as vertices in a graph with edges representing links between pages.  PageRank ranks webpages based on the link structure; important webpages are linked to by other important webpages [6].  This idea is extended to sentences in a document; important sentences are similar to other important sentences.  TextRank and LexRank are two algorithms that rank sentences based on this idea [2][5].  These two algorithms represent sentences in a document as vertices and edges based on a distance metric between sentences.  LexRank uses unweighted edges between sentences if the two sentences meets some minimum distance threshold using cosine distance.  TextRank uses weighted edges based on the shared number of words normalized by the log lengths of the sentences.  We chose TextRank based on its unsupervised nature and the absence of parameters to tweak.  We give a more detailed description of the TextRank algorithm in the next section.

\section*{Introduction to TextRank}
The TextRank method is based on the PageRank algorithm.  The original PageRank algorithm is based around the idea of a random websurfer [9]; how likely are they to end up at a particular page by following hyperlinks?  The original PageRank algorithm worked on graphs with unweighted edges and the PageRank of a particular page was given by $rank(v_i) = (1 - d) + d \Sigma_{j \in in(v_i)} \frac{rank(v_j)}{|out(v_j)|}$ where $v_i$ and $v_j$ represent webpages, $in(v_j)$ represents the set of vertices that links to page $i$, $out(v_j)$ represents the pages that link from page $j$, and $d$ represents the dampening factor.  The dampening factor represents the websurfer jumping to a random page.\\
\\
TextRank represents sentences as vertices and edges between sentences is weighted by the following distance function: $d(s_i, s_j) = \frac{|\{w_k | w_k \in s_i & w_k \in s_j \}|}{log(|s_i|) + log(|s_j|)}$.  $s_i$ and $s_j$ represent sentence $i$ and sentence $j$.  Each sentence is a set of sets and the distance metric is the cardinality of the intersection between two sentence sets divided by the sum of the logs of the sentence lengths.  This distance function for edge weights introduces a seperate issue: the original PageRank algorithm is for unweighted graphs.  In order to get around this issue a weighted variation of PageRank is used: $rank(s_i) = (1 - d) + d \Sigma_{s_j \in In(s_i)} \frac{w_{ji}}{\Sigma_{s_k \in out(s_j)} rank(s_j)}$.  $s_i$ and $s_j$ represent sentence $i$ and sentence $j$ and $w_{ji}$ represents the edge weight between sentence $j$ and $i$.  It turns out with this slight modification we can iteratively calculate the page rank of sentences in a document.

\section*{Implementation and Java Code}
Before running the TextRank algorithm some basic text preprocessing was done.  Punctuation was stripped from the text and stop words, words with little semantic meaning, were removed from the text using the Lucene library [7].  The text was parsed into individual sentences using the openNLP library.  The adjacency matrix was calculated between all sentences.  The adjacency matrix was normalized so that the columns sum to one and then the weighted pagerank is calculated iteratively.\\
\\
Our Java implementation of TextRank is split into seven java class files. The most important file is the SummaryBot.java file that defines a SummaryBot object. A SummaryBot is meant to take in a string or a text file containing an article and summarize it down to just a few sentences. To do this it first extracts the text from the file and then sends it to a ISentenceProcessor object.  The SentenceProcessor object is to separate the text into sentences and remove unnecessary or irrelevant words.  Initially sentence processing was done solely in openNLP with OpenNLPSentenceProcessor.java.  However, openNLP does not have stop word removal and we used part-of-speech tagging to accomplish the same task.  Due to computation time and better stop word removal we implemented the sentence processing with both libraries and this is contained in LuceneSentenceProcessor.java.\\
\\
After being processed, the sentences are passed to the CreateCommonMatrix method in MiscUtils.java which creates an adjacency matrix $A$ where $a_{i, j}$ represents the number of words shared between sentences i and j.  Then the matrix is sent to the IRanker object which uses some method to rank the sentences based on values in the matrix. We implemented using the PageRanker class which iteratively calculates the weighted page rank to accomplish this task. Finally, with the results from the Ranker object, the SummaryBot is able to print the best sentences for summarizing the article.  All of the java source code can be found at our repository: \url{http://www.github.com/ALShum/textsummary}.\\
\\
As a final heuristic, SummaryBot returns the top sentences in the same order that they appear in the original 	article text.  When sentences were returned based strictly on highest PageRank, it was quite common for the top sentence to make a reference to something that appeared earlier in the article.  By returning sentences in the same order as the text in the article it increases the likelihood that the summary sentences will follow the same logical ordering as the original text.

\section*{Results}
Since this is not a supervised algorithm testing the results was not straightforward.  We did not have the resources to compare TextRank's results with human results.  There are a few numerical measures used to evaluation performance based on N-gram statistics.  Our goal was to have more interpretable results and we compare our implementation of TextRank against ``the competition'' -- other available text summerizers.  We compare our results against the following online text summarizers:
\begin{enumerate}
\item \url{http://freesummarizer.com/}
\item \url{http://autosummarizer.com/}
\item \url{http://textcompactor.com/}
\end{enumerate}

For evaluation purposes we randomly choose the following six news articles from various sources:
\begin{enumerate}
\item \url{http://www.reuters.com/article/2014/12/04/us-vatican-economy-pell idUSKCN0JI1CG20141204?feedType=RSS&feedName=worldNews}
\item \url{http://thinkprogress.org/climate/2014/12/04/3599528/cruise-lines-sewage-2014/}
\item \url{http://articles.economictimes.indiatimes.com/2014-12-02/news/56648982_1_syria-british-man-jihadis}
\item \url{http://www.thelocal.de/20141204/merkel-speaks-out-against-net-neutrality}
\item \url{http://www.bbc.com/news/world-europe-30322198}
\item \url{http://www.aljazeera.com/news/middleeast/2014/11/us-led-air-raids-target-syria-rebel-groups-2014116123052671427.html}
\end{enumerate}

We use our implementation of TextRank against other online text summarizers for the articles mentioned above.  We check the similarity in terms of the number of matched sentences between the above summarizers and TextRank.  Complete results can be found at our repository: \url{http://www.github.com/ALShum/textsummary/blob/master/Results.txt}.
\\
The following is a summary of the results. 

Note: it's necessary to add how many sentences could have been smilar since the online summarizers sometimes use less than five sentences.\\
\\
Article 1:\\summarizer 2: 1 out of 3 sentences were similar\\summarizer 3: 1 out of 4 sentences were similar\\summarizer 4: 0 out of 5 sentences were similar\\
\\
Although 4 of the 5 sentences our summarizer came up with were different, they still centered around the article's main topic.\\
\\
Article 2:\\summarizer 2: 2 out of 4 sentences were similar\\summarizer 3: 2 out of 5 sentences were similar\\summarizer 4: 1 out of 5 sentences were similar\\
\\
Again, the three sentences that weren't similar still provide important knowledge to the summary.\\
\\
Article 3:\\summarizer 2: 0 out of 4 sentences were similar\\summarizer 3: 0 out of 5 sentences were similar\\summarizer 4: 2 out of 5 sentences were similar\\
\\
In this article, none of the summarizers had very many similar sentences to eachother, but all summarized it well.
\\
Article 4:\\summarizer 2: 3 out of 5 sentences were similar\\summarizer 3: 3 out of 5 sentences were similar\\summarizer 4: 2 out of 5 sentences were similar\\
\\
The two sentences not similar were still good pieces of information.\\
\\
Article 5:\\summarizer 2: 2 out of 5 sentences were similar\\summarizer 3: 3 out of 5 sentences were similar\\summarizer 4: 0 out of 5 sentences were similar\\
\\
For whatever reason, in this article The last online summarizer did a poor job of summarizing, so it's probably good it didn't share any similar sentences with ours.\\
\\
Article 6:\\summarizer 2: 3 out of 4 sentences were similar\\summarizer 3: 3 out of 4 sentences were similar\\summarizer 4: 4 out of 5 sentences were similar\\
\\
In this article only 1 sentences was not also summarized by the other ones.

\section*{Conclusion}

\section*{Sources}

%citation
%overview
%1. http://pages.cs.wisc.edu/~goldberg/publications/summarization.pdf
%textrank
%2. http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf
%supervised
%3. http://www.extractor.com/IR2000.pdf
%LSA
%4. http://www.kiv.zcu.cz/~jstein/publikace/isim2004.pdf
%lexrank
%5. http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html
%pagerank
%6. http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf
%7. Lucene
%8. OpenNLP
%page rank links:
%9 http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf
%10 http://www.cs.princeton.edu/~chazelle/courses/BIB/pagerank.htm

\end{document}